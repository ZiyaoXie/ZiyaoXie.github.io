<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Database on 提笔忘字</title><link>https://imx.ink/database/</link><description>Recent content in Database on 提笔忘字</description><generator>Hugo</generator><language>zh-CN</language><copyright>Copyright © 2023, Xie Ziyao.</copyright><lastBuildDate>Sat, 11 May 2024 18:00:00 +0800</lastBuildDate><atom:link href="https://imx.ink/database/index.xml" rel="self" type="application/rss+xml"/><item><title>数据库事务测试工具</title><link>https://imx.ink/tech/2024/05/11/database-transaction-testing-tools/</link><pubDate>Sat, 11 May 2024 18:00:00 +0800</pubDate><guid>https://imx.ink/tech/2024/05/11/database-transaction-testing-tools/</guid><description>&lt;h2 id="数据库事务测试工具">数据库事务测试工具&lt;/h2>
&lt;p>参考资料：&lt;a href="https://cn.pingcap.com/blog/tag/transaction-frontier-research/">TiDB-事务前沿研究&lt;/a>；&lt;/p>
&lt;table>
 &lt;thead>
 &lt;tr>
 &lt;th>分类&lt;/th>
 &lt;th>名称&lt;/th>
 &lt;th>描述&lt;/th>
 &lt;/tr>
 &lt;/thead>
 &lt;tbody>
 &lt;tr>
 &lt;td>事务一致性测试&lt;/td>
 &lt;td>&lt;a href="https://github.com/pingcap/tipocket/tree/master/testcase/bank">Bank&lt;/a>&lt;/td>
 &lt;td>银行测试是模拟一个银行系统中的转账流程。
&lt;br>&lt;br>
在这个测试中，我们创建一系列模拟银行账户，并随时选择两个账户使用事务进行相互转账，一个账户减去一定的金额，另一个账户增加对应的金额，这样的交易不断的并发执行着。在快照隔离下，所有的转账都必须保证每一个时刻所有的账户的总金额是相同的。&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>事务一致性测试&lt;/td>
 &lt;td>&lt;a href="https://github.com/anishathalye/porcupine">Porcupine&lt;/a>&lt;/td>
 &lt;td>Porcupine 一个用 Go 实现的线性一致性验证工具。
&lt;br>&lt;br>
是基于 P-compositionality 算法，P-compositionality 算法利用了线性一致性的 Locality 原理，即如果一个调用历史的所有子历史都满足线性一致性，那么这个历史本身也满足线性一致性。因此，可以将一些不相关的历史划分开来，形成多个规模更小的子历史，转而验证这些子历史的线性一致性。&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>事务隔离级别测试&lt;/td>
 &lt;td>&lt;a href="https://github.com/jepsen-io/elle">Elle&lt;/a>&lt;/td>
 &lt;td>Elle 是用来验证数据库事务隔离级别的检查工具。
&lt;br>&lt;br>
Elle 是一个纯黑盒的测试工具，巧妙的构造了一个测试场景，通过客户端生成的历史构造出依赖关系图，通过判断依赖图中是否有环以及分析环来确定事务的出现的异常类型，来确定事务的隔离级别。&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>事务隔离级别测试&lt;/td>
 &lt;td>&lt;a href="https://github.com/postgres/postgres/tree/master/src/test/isolation">pg_isolation_regress&lt;/a>&lt;/td>
 &lt;td>包含一组针对 PostgreSQL 中并发行为的测试。
&lt;br>&lt;br>
这些测试需要运行多个交互事务，这需要管理多个并发连接，因此无法使用常规 pg_regress 程序进行测试。主要测试可序列化隔离级别，也添加了针对其他类型并发行为的测试。&lt;/td>
 &lt;/tr>
 &lt;/tbody>
&lt;/table></description></item><item><title>数据库测什么与怎么测</title><link>https://imx.ink/tech/2024/04/22/what-and-how-to-test-the-database/</link><pubDate>Mon, 22 Apr 2024 18:00:00 +0800</pubDate><guid>https://imx.ink/tech/2024/04/22/what-and-how-to-test-the-database/</guid><description>&lt;h2 id="数据库测什么与怎么测">数据库测什么与怎么测&lt;/h2>
&lt;p>传说中有三个问题能直击灵魂：“你是谁？从哪来？到哪去？”&lt;/p>
&lt;p>对于测试人员来说，“你是谁”这个问题已经解决了，剩下两个问题也随之变成了“测什么”和“怎么测”。&lt;/p>
&lt;h2 id="测什么">测什么&lt;/h2>
&lt;p>如果从代码开始，由内而外进行总结的话，数据库的测试，可以分为以下层次。&lt;/p>
&lt;table>
 &lt;thead>
 &lt;tr>
 &lt;th>序号&lt;/th>
 &lt;th>测试项&lt;/th>
 &lt;th>说明&lt;/th>
 &lt;/tr>
 &lt;/thead>
 &lt;tbody>
 &lt;tr>
 &lt;td>0&lt;/td>
 &lt;td>代码静态检查&lt;/td>
 &lt;td>根据所选择的开发语言，可以根据已制定的开发规范选择相应的自动化检查工具，在代码合并到主仓库之前完成检查。&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>1&lt;/td>
 &lt;td>基于编译器的检查，sanitizers&lt;/td>
 &lt;td>无论是传统一些的 valgrind，还是现在开始流行的 google sanitizers，都能够在产品走向生产环境之前，暴露出一些内存、线程等相关问题。
&lt;br>&lt;br>
严格来讲这些问题的暴露是需要和丰富的测例库配合的，但由于 sanitizers 需要在编译时打开相关的选项，所以笔者选择将其放在紧挨着代码静态检查的地方。&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>2&lt;/td>
 &lt;td>单元测试&lt;/td>
 &lt;td>这是最贴近代码的测试形式，能一定程度保证被测试单元的质量，减少低级错误所引发的 bug。&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>3&lt;/td>
 &lt;td>Assert&lt;/td>
 &lt;td>如果说单元测试保证的是零件的质量，合理并必要的 Debug Assert 则能够通过检查关键变量是否为合理值，从而尽早地检查出零件组合之后存在的问题。&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>4&lt;/td>
 &lt;td>基本功能测试（冒烟测试）&lt;/td>
 &lt;td>这个阶段的测试内容，主要是保证数据库能够像一个数据库一样运行，能够像一个数据库一样对用户的操作作出反应。&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>5&lt;/td>
 &lt;td>SQL 逻辑测试&lt;/td>
 &lt;td>一般而言，SQL 逻辑测试是数据库测试的重中之重，因为如果 SQL 语句执行的结果有问题，数据库其他特性做得再好也没有意义了。
&lt;br>&lt;br>
可以说数据库领域的新人和新产品是十分幸运的，因为市面上有很多成熟的开源数据库，在开源了代码的同时也开源了它们的海量测例，后来者可以直接用测例来验证自己的数据库产品。&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>6&lt;/td>
 &lt;td>SQL 混淆测试&lt;/td>
 &lt;td>混淆测试即 Fuzz 测试，算是 SQL 逻辑测试的延伸，主要思路是通过分析语法树自动生成大量随机的 SQL 语句，对数据库解析器的解析能力进行考验。
&lt;br>&lt;br>
现在主要有两种思路：一种是不关心语句执行结果，只检查解析器是否存在可能导致崩溃的 bug；另一种则是按照特定的算法生成语句，能够根据算法推断出语句的执行结果，再跟数据库实际返回的结果做比较。&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>7&lt;/td>
 &lt;td>压力测试&lt;/td>
 &lt;td>无故障场景下的稳定性测试，测试的手段一般都很简单，基本是通过其他工具程序模拟出长时间、高并发、高频率的客户端动作。
&lt;br>&lt;br>
具体可以大致分为 CPU 资源紧张、磁盘资源紧张、内存资源紧张等几个测试方向，重点观察数据库在一般压力情况下和高压情况下，是否会出现语句执行结果出错、非预期的死锁、性能相关指标变化不符合预期等问题。&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>8&lt;/td>
 &lt;td>故障模拟测试&lt;/td>
 &lt;td>在没有数据副本的情况下，故障模拟测试一般都围绕着数据安全性进行，确认故障发生时已提交的事务数据不丢失，未提交的数据不能生效。
&lt;br>&lt;br>
故障形式一般以通过 kill 命令杀死数据库进程为主。&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>9&lt;/td>
 &lt;td>性能测试&lt;/td>
 &lt;td>固定场景下测试并记录数据，待新版本发布时进行回归对比。&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>10&lt;/td>
 &lt;td>事务属性相关测试&lt;/td>
 &lt;td>事务的 ACID 四个属性，其中 ACD 三个属性都很好测试验证，剩下的 I 则无论是测试难度还是对数据库的重要性，都是四个属性中最高的。
&lt;br>&lt;br>
基于传统的 ANSI 标准定义的隔离级，RC 和 Serializable 的定义清晰，相对比较容易设计测例编写测试工具；但 RR 隔离级则含糊得很，需要开发与测试人员共同参考一些比较新的论文，共同确认所研发的数据库 RR 隔离级具体能避免哪些问题，不能避免哪些问题。&lt;/td>
 &lt;/tr>
 &lt;/tbody>
&lt;/table>
&lt;h2 id="怎么测">怎么测&lt;/h2>
&lt;p>或者具体地说，我们需要编写怎样的测试工具。&lt;/p></description></item><item><title>数据库分库分表</title><link>https://imx.ink/tech/2023/06/28/database-sharding/</link><pubDate>Wed, 28 Jun 2023 12:48:00 +0800</pubDate><guid>https://imx.ink/tech/2023/06/28/database-sharding/</guid><description>&lt;h2 id="数据库分库分表">数据库分库分表&lt;/h2>
&lt;p>分库分表在解决如 IO 瓶颈、读写性能、物理存储瓶颈、内存瓶颈、单机故障影响面等问题的同时，也带来如事务性、主键冲突、跨库 join、跨库聚合查询等问题。&lt;/p>
&lt;p>在综合业务场景考虑，正如缓存的使用一样，本着非必须勿使用原则。如数据库确实成为性能瓶颈时，在设计分库分表方案时也应充分考虑方案的扩展性，或者考虑采用成熟热门的分布式数据库解决方案。&lt;/p>
&lt;h2 id="什么是分库分表">什么是分库分表&lt;/h2>
&lt;p>分库：将一个数据库中的数据按照某种规则分拆到多个数据库中，以缓解单服务器的压力（CPU、内存、磁盘、IO）。&lt;/p>
&lt;p>分表：将一个表中的数据按照某种规则分拆到多张表中，降低锁粒度以及索引树，提升数据查询效率。&lt;/p>
&lt;h2 id="为什么分库分表">为什么分库分表&lt;/h2>
&lt;p>性能角度：CPU、内存、磁盘、IO瓶颈；随着业务体量扩大，数据规模达到百万行，数据库索引树庞大，查询性能出现瓶颈；用户并发流量规模扩大，由于单库（单服务器）物理性能限制也无法承载大流量。&lt;/p>
&lt;p>可用性角度：单机故障率影响面；如果是单库，数据库宕机会导致100%服务不可用，N 库则可以将影响面降低 N 倍。&lt;/p>
&lt;h2 id="分库分表带来的问题">分库分表带来的问题&lt;/h2>
&lt;p>事务性问题：分库可能导致执行一次事务所需的数据分布在不同服务器上，数据库层面无法实现事务性操作，需要更上层业务引入分布式事务操作，难免会给业务带来一定复杂性。&lt;/p>
&lt;p>主键（自增 ID）唯一性问题：在数据库表设计时，经常会使用自增ID作为数据主键，这就导致后续在迁库迁表或者分库分表操作时，会因为主键的变化或者主键不唯一产生冲突。&lt;/p>
&lt;p>跨库多表 join 问题：join 操作往往会给后续的分库分表操作带来各种问题，可能导致数据的死锁。&lt;/p>
&lt;p>跨库聚合查询问题：分库分表会导致常规聚合查询操作，如&lt;code>group by&lt;/code>，&lt;code>order by&lt;/code>等变得异常复杂。&lt;/p>
&lt;h2 id="什么是好的分库分表方案">什么是好的分库分表方案&lt;/h2>
&lt;p>满足业务场景需要：根据业务场景的不同选择不同分库分表方案，比如按照时间划分、按照用户ID划分、按照业务能力划分等。&lt;/p>
&lt;p>方案可持续性：业务数据量级和流量量级未来进一步达到新的量级的时候，我们的分库分表方案可以持续灵活扩容处理。&lt;/p>
&lt;p>最小化数据迁移：扩容时一般涉及到历史数据迁移，其扩容后需要迁移的数据量越小其可持续性越强，理想的迁移前后的状态是（同库同表 &amp;gt; 同表不同库 &amp;gt; 同库不同表 &amp;gt; 不同库不同表）。&lt;/p>
&lt;p>最小化数据偏斜：数据在库表中分配的均衡性，尽可能保证数据流量在各个库表中保持等量分配，避免热点数据对于单库造成压力；&lt;code>最大数据偏斜率=(数据量最大样本-数据量最小样本)/数据量最小样本&lt;/code>，一般来说，如果我们的最大数据偏斜率在5%以内是可以接受的。&lt;/p>
&lt;h2 id="如何分库分表">如何分库分表&lt;/h2>
&lt;h3 id="垂直拆分">垂直拆分&lt;/h3>
&lt;p>垂直拆表：即大表拆小表，将一张表中数据不同“字段”分拆到多张表中，比如商品库将商品基本信息、商品库存、卖家信息等分拆到不同库表中；考虑因素有将不常用的、数据较大、长度较长（比如 text 类型字段）的拆分到“扩展表“，表和表之间通过”主键外键“进行关联；好处是降低表数据规模，提升查询效率，也避免查询时数据量太大造成的“跨页”问题。&lt;/p>
&lt;p>垂直拆库：在垂直拆表的基础上，将一个系统中的不同业务场景进行拆分，比如订单表、用户表、商品表；好处是降低单数据库服务的压力（物理存储、内存、IO等）、降低单机故障的影响面。&lt;/p>
&lt;h3 id="水平拆分">水平拆分&lt;/h3>
&lt;p>将总体数据按照某种维度（时间、用户）等分拆到多个库中或者表中，如订单按照（日期、用户ID、区域）分库分表。&lt;/p>
&lt;p>水平拆表：将数据按照某种维度拆分为多张表，但是由于多张表还是从属于一个库，其降低锁粒度，一定程度提升查询性能，但是仍然会有 IO 性能瓶颈。&lt;/p>
&lt;p>水平拆库：将数据按照某种维度分拆到多个库中，降低单机单库的压力，提升读写性能。&lt;/p></description></item></channel></rss>